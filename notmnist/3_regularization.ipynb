{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in _notmist.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    # 3x2x3\n",
    "    # array=[\n",
    "    #        [\n",
    "    #         [1,2,3],\n",
    "    #         [4,5,6]\n",
    "    #        ],\n",
    "    #        [\n",
    "    #         [7,8,9],\n",
    "    #         [10,11,12]\n",
    "    #        ],\n",
    "    #        [\n",
    "    #         [13,14,15]\n",
    "    #         [16,17,18]\n",
    "    #        ],\n",
    "    #       ]\n",
    "    # after array.reshape(-1, 2 * 3)\n",
    "    # reslut=[[1,2,3,4,5,6],\n",
    "    #         [7,8,9,10,11,12]\n",
    "    #         [13,14,15,16,17,18]\n",
    "    #        ]\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    \n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    # np.arrange(10): category = [0,1,2,3,4,5,6,7,8,9]\n",
    "    # category == 4 => [False, False, False, False,  True, False, False, False, False, False]\n",
    "    # (category == 4).astype(np.float32) => [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]\n",
    "    # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with l2 loss function\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# regularizing with beta = 0.01\n",
    "\n",
    "# multinomial logistic regression\n",
    "train_subset = 10000\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables    \n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    \n",
    "    # loss function using l2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases )\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 46.506275\n",
      "Training accuracy: 9.5%\n",
      "Validation accuracy: 13.3%\n",
      "Loss at step 100: 11.777938\n",
      "Training accuracy: 74.1%\n",
      "Validation accuracy: 73.1%\n",
      "Loss at step 200: 4.478943\n",
      "Training accuracy: 79.3%\n",
      "Validation accuracy: 77.6%\n",
      "Loss at step 300: 1.983642\n",
      "Training accuracy: 82.4%\n",
      "Validation accuracy: 80.3%\n",
      "Loss at step 400: 1.133908\n",
      "Training accuracy: 83.7%\n",
      "Validation accuracy: 81.5%\n",
      "Loss at step 500: 0.841569\n",
      "Training accuracy: 84.0%\n",
      "Validation accuracy: 82.0%\n",
      "Loss at step 600: 0.739828\n",
      "Training accuracy: 84.2%\n",
      "Validation accuracy: 82.3%\n",
      "Loss at step 700: 0.704094\n",
      "Training accuracy: 84.4%\n",
      "Validation accuracy: 82.3%\n",
      "Loss at step 800: 0.691447\n",
      "Training accuracy: 84.4%\n",
      "Validation accuracy: 82.4%\n",
      "Test accuracy: 89.1%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "\n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(\n",
    "            predictions, train_labels[:train_subset, :]))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy( valid_prediction.eval(), valid_labels) )\n",
    "\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network wiht l2 loss function\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]) )\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 47.935638\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 14.0%\n",
      "Minibatch loss at step 500: 0.866493\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1000: 0.671214\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 1500: 0.931760\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2000: 0.801875\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 0.615229\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 3000: 0.746723\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 88.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log reg with l2 loss and small training data\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multinomial logistic regression \n",
    "\n",
    "train_subset = 100\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables    \n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    \n",
    "    # loss function using l2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(tf_valid_dataset, weights) + biases )\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 50.424183\n",
      "Training accuracy: 10.0%\n",
      "Validation accuracy: 11.0%\n",
      "Loss at step 100: 11.088320\n",
      "Training accuracy: 100.0%\n",
      "Validation accuracy: 45.4%\n",
      "Loss at step 200: 4.136235\n",
      "Training accuracy: 100.0%\n",
      "Validation accuracy: 52.4%\n",
      "Loss at step 300: 1.596785\n",
      "Training accuracy: 100.0%\n",
      "Validation accuracy: 59.5%\n",
      "Loss at step 400: 0.671136\n",
      "Training accuracy: 100.0%\n",
      "Validation accuracy: 63.9%\n",
      "Loss at step 500: 0.333710\n",
      "Training accuracy: 100.0%\n",
      "Validation accuracy: 66.3%\n",
      "Loss at step 600: 0.210482\n",
      "Training accuracy: 100.0%\n",
      "Validation accuracy: 67.4%\n",
      "Loss at step 700: 0.165306\n",
      "Training accuracy: 100.0%\n",
      "Validation accuracy: 68.1%\n",
      "Loss at step 800: 0.148624\n",
      "Training accuracy: 100.0%\n",
      "Validation accuracy: 68.3%\n",
      "Test accuracy: 75.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "\n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(\n",
    "            predictions, train_labels[:train_subset, :]))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy( valid_prediction.eval(), valid_labels) )\n",
    "\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "    \n",
    "# Training accuracy goes to 100% due to the small sample size, \n",
    "# however, the model is not as good the validation samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network with l2 loss and small training data\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]) )\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 51.832253\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 12.8%\n",
      "Minibatch loss at step 500: 0.575074\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 0.339519\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 1500: 0.286044\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 2000: 0.270461\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 2500: 0.262154\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 3000: 0.266884\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Test accuracy: 83.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "train_dataset_2 = train_dataset[:500, :]\n",
    "train_labels_2 = train_labels[:500]\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels_2.shape[0] - batch_size)\n",
    "        \n",
    "        batch_data = train_dataset_2[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels_2[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "# We see overfitting occuring on neural network model when the training set is 3 times smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer\n",
    "    hidden_nodes = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable( tf.truncated_normal([hidden_nodes, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_relu = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(valid_relu, weights) + biases) \n",
    "\n",
    "    test_relu = tf.nn.relu(tf.matmul( tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 457.210358\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 32.6%\n",
      "Minibatch loss at step 500: 32.717113\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1000: 14.430128\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1500: 11.899036\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 2000: 11.126209\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 2500: 3.144731\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 3000: 5.168482\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.1%\n",
      "Test accuracy: 86.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : 0.5}\n",
    "        _, l, predictions = session.run( [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy( valid_prediction.eval(), valid_labels) )\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 515.042542\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 25.9%\n",
      "Minibatch loss at step 500: 3.100446\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 1000: 1.869233\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1500: 1.163270\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 2000: 0.742715\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 2500: 0.488512\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3000: 0.347113\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Test accuracy: 84.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "train_dataset_2 = train_dataset[:500, :]\n",
    "train_labels_2 = train_labels[:500]\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels_2.shape[0] - batch_size)\n",
    "        \n",
    "        batch_data = train_dataset_2[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels_2[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : 0.5}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying smaller beta and bigger num steps\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.0001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer\n",
    "    hidden_nodes = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    hidden_layer = tf.nn.relu( tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable( tf.truncated_normal([hidden_nodes, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop, weights) + biases\n",
    "    loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean( loss + beta * tf.nn.l2_loss(weights) )\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_relu = tf.nn.relu(  tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(valid_relu, weights) + biases) \n",
    "\n",
    "    test_relu = tf.nn.relu( tf.matmul( tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 490.814728\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 29.9%\n",
      "Minibatch loss at step 500: 43.036697\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1000: 20.025515\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1500: 11.937448\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 11.924856\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2500: 4.176146\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 3000: 3.977453\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 3500: 8.576484\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 4000: 7.854161\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 4500: 9.309613\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 5000: 0.971546\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 5500: 3.964468\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 6000: 1.100278\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Test accuracy: 88.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 6001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : 0.5}\n",
    "        _, l, predictions = session.run( [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy( valid_prediction.eval(), valid_labels) )\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying keep prob of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer\n",
    "    hidden_nodes = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_nodes, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_relu = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(valid_relu, weights) + biases) \n",
    "\n",
    "    test_relu = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 1133.790283\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 33.3%\n",
      "Minibatch loss at step 500: 457087.625000\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 69.5%\n",
      "Minibatch loss at step 1000: 14255584.000000\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 72.0%\n",
      "Minibatch loss at step 1500: 244643632.000000\n",
      "Minibatch accuracy: 36.7%\n",
      "Validation accuracy: 69.1%\n",
      "Minibatch loss at step 2000: 22856202240.000000\n",
      "Minibatch accuracy: 44.5%\n",
      "Validation accuracy: 70.1%\n",
      "Minibatch loss at step 2500: 264826830848.000000\n",
      "Minibatch accuracy: 45.3%\n",
      "Validation accuracy: 71.9%\n",
      "Minibatch loss at step 3000: 12656340631552.000000\n",
      "Minibatch accuracy: 43.0%\n",
      "Validation accuracy: 66.0%\n",
      "Test accuracy: 72.1%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : 0.1}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy( valid_prediction.eval(), valid_labels) )\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with learning rate and multiple keep probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer\n",
    "    hidden_nodes = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_nodes, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "\n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 100000, 0.95, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_relu = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(valid_relu, weights) + biases) \n",
    "\n",
    "    test_relu = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>with keep prob of 0.5\n",
      "Initialized\n",
      "Minibatch loss at step 0: 518.856323\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 31.6%\n",
      "Minibatch loss at step 500: 38.629776\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 16.603941\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1500: 11.881701\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 2000: 13.558303\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 2500: 3.389016\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 3000: 8.321461\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.9%\n",
      "Test accuracy: 86.7%\n",
      ">>with keep prob of 0.6\n",
      "Initialized\n",
      "Minibatch loss at step 0: 449.093201\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 30.4%\n",
      "Minibatch loss at step 500: 14.470038\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1000: 24.393856\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1500: 12.268685\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2000: 13.517012\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2500: 4.055869\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 4.091739\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.0%\n",
      "Test accuracy: 87.3%\n",
      ">>with keep prob of 0.7\n",
      "Initialized\n",
      "Minibatch loss at step 0: 377.501007\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 31.2%\n",
      "Minibatch loss at step 500: 27.863613\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1000: 14.230073\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1500: 9.224967\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2000: 14.483100\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2500: 2.173989\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 3000: 3.930125\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Test accuracy: 88.4%\n",
      ">>with keep prob of 0.9\n",
      "Initialized\n",
      "Minibatch loss at step 0: 376.641663\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 28.0%\n",
      "Minibatch loss at step 500: 23.206573\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1000: 13.631821\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1500: 7.254698\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 12.663574\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 2500: 2.455381\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 3000: 4.237711\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.9%\n",
      "Test accuracy: 89.0%\n",
      ">>with keep prob of 0.9\n",
      "Initialized\n",
      "Minibatch loss at step 0: 334.366486\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 26.4%\n",
      "Minibatch loss at step 500: 23.707047\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1000: 19.539637\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 9.367361\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 6.474187\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2500: 2.184952\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 3000: 2.734607\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.9%\n",
      "Test accuracy: 89.0%\n",
      ">>with keep prob of 1.0\n",
      "Initialized\n",
      "Minibatch loss at step 0: 415.412231\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 39.4%\n",
      "Minibatch loss at step 500: 15.871975\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 12.445210\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1500: 10.366711\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2000: 5.629319\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 2500: 2.063935\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 3000: 5.290089\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "Test accuracy: 89.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "for kp in [0.5, 0.6, 0.7, 0.9, 0.9, 1.0]:\n",
    "    print(\">>with keep prob of \" + str(kp))\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : kp}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "              print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "              print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "              print(\"Validation accuracy: %.1f%%\" % accuracy( valid_prediction.eval(), valid_labels) )\n",
    "        print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer\n",
    "    hidden_nodes = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_nodes, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "\n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learnr = tf.placeholder(\"float\")\n",
    "    learning_rate = tf.train.exponential_decay(learnr, global_step, 100000, 0.95, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_relu = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(valid_relu, weights) + biases) \n",
    "\n",
    "    test_relu = tf.nn.relu(tf.matmul( tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>trying lr of 0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 385.842987\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 40.5%\n",
      "Minibatch loss at step 500: 11.926297\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1000: 13.397211\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 8.116122\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2000: 11.611623\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 1.583406\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 3000: 2.704599\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.8%\n",
      "Test accuracy: 88.8%\n",
      ">>trying lr of 0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 374.371277\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 33.7%\n",
      "Minibatch loss at step 500: 13.115983\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1000: 18.906265\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1500: 7.417068\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2000: 13.330383\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2500: 2.396241\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 3000: 3.483723\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.8%\n",
      ">>trying lr of 0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 350.194977\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 24.4%\n",
      "Minibatch loss at step 500: 21.507524\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1000: 14.528177\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 1500: 10.707889\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2000: 10.401804\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 2500: 1.782124\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 3000: 2.987957\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.1%\n",
      "Test accuracy: 88.7%\n",
      ">>trying lr of 0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 319.782227\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 26.5%\n",
      "Minibatch loss at step 500: 17.461103\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1000: 19.653761\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 8.569845\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2000: 9.916937\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 2500: 1.299696\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 3000: 3.044155\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.7%\n",
      "Test accuracy: 88.9%\n",
      ">>trying lr of 0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 317.507996\n",
      "Minibatch accuracy: 18.0%\n",
      "Validation accuracy: 23.2%\n",
      "Minibatch loss at step 500: 23.807425\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1000: 21.647875\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 1500: 8.836923\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2000: 12.766138\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2500: 2.649219\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 3000: 2.848309\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 87.9%\n",
      ">>trying lr of 0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 319.170471\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 32.0%\n",
      "Minibatch loss at step 500: 15.015936\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1000: 7.823966\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1500: 10.410268\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2000: 12.001974\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2500: 1.645918\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 3000: 3.056951\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 88.6%\n",
      ">>trying lr of 0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 360.235870\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 34.4%\n",
      "Minibatch loss at step 500: 19.622259\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1000: 19.491827\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 8.310833\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 12.739081\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 2500: 3.130910\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 3000: 2.412362\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.2%\n",
      "Test accuracy: 88.8%\n",
      ">>trying lr of 0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 338.423920\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 25.4%\n",
      "Minibatch loss at step 500: 21.840858\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1000: 19.806187\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1500: 7.609854\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2000: 8.465682\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 2500: 2.914923\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 3000: 3.037869\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.9%\n",
      "Test accuracy: 89.4%\n",
      ">>trying lr of 0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 401.009918\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 27.8%\n",
      "Minibatch loss at step 500: 20.581774\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1000: 14.774067\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 7.192035\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 2000: 9.826937\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 2.498019\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 3000: 2.741783\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 82.7%\n",
      "Test accuracy: 89.2%\n"
     ]
    }
   ],
   "source": [
    "for lr in np.arange(0.0001, 0.001, 0.0001).tolist():\n",
    "\n",
    "    print('>>trying lr of ' + str(lr))\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : 1.0, learnr : lr}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "              print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "              print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "              print(\"Validation accuracy: %.1f%%\" % accuracy( valid_prediction.eval(), valid_labels) )\n",
    "        print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying 2 layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "hidden_nodes1 = 1024\n",
    "hidden_nodes2 = 512\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer 1\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes1]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes1]))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "    \n",
    "    # new hidden layer 2\n",
    "    hidden_weights2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2]) )\n",
    "    hidden_biases2 = tf.Variable(tf.zeros([hidden_nodes2]))\n",
    "    hidden_layer2 = tf.nn.relu(tf.matmul( hidden_layer_drop, hidden_weights2) + hidden_biases2)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    hidden_layer_drop2 = tf.nn.dropout(hidden_layer2, keep_prob)\n",
    "    \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_nodes2, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop2, weights) + biases\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "\n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learnr = tf.placeholder(\"float\")\n",
    "    learning_rate = tf.train.exponential_decay(learnr, global_step, 100000, 0.95, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step= global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)    \n",
    "    \n",
    "    valid_relu1 = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)    \n",
    "    valid_relu2 = tf.nn.relu(tf.matmul(valid_relu1, hidden_weights2) + hidden_biases2)    \n",
    "    \n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(valid_relu2, weights) + biases) \n",
    "    \n",
    "    test_relu1 = tf.nn.relu(tf.matmul( tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_relu2 = tf.nn.relu(tf.matmul( test_relu1, hidden_weights2) + hidden_biases2)   \n",
    "    \n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu2, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 6134.153809\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.5%\n",
      "Minibatch loss at step 500: 307.032623\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 1000: 217.596283\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 1500: 342.984344\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 238.399216\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2500: 88.152672\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 115.266457\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.6%\n",
      "Test accuracy: 87.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : 1.0, learnr : 0.001}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict )\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "hidden_nodes1 = 1024\n",
    "hidden_nodes2 = 512\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer 1\n",
    "    \n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes1]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes1]))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "    \n",
    "    # new hidden layer 2\n",
    "    hidden_weights2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2]) )\n",
    "    hidden_biases2 = tf.Variable(tf.zeros([hidden_nodes2]))\n",
    "    hidden_layer2 = tf.nn.relu(tf.matmul( hidden_layer_drop, hidden_weights2) + hidden_biases2)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    hidden_layer_drop2 = tf.nn.dropout(hidden_layer2, keep_prob)\n",
    "    \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_nodes2, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop2, weights) + biases\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "\n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learnr = tf.placeholder(\"float\")\n",
    "    learning_rate = tf.train.exponential_decay(learnr, global_step, 100000, 0.95, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step= global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)    \n",
    "    \n",
    "    valid_relu1 = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)    \n",
    "    valid_relu2 = tf.nn.relu(tf.matmul(valid_relu1, hidden_weights2) + hidden_biases2)    \n",
    "    \n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(valid_relu2, weights) + biases) \n",
    "    \n",
    "    test_relu1 = tf.nn.relu(tf.matmul( tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_relu2 = tf.nn.relu(tf.matmul( test_relu1, hidden_weights2) + hidden_biases2)   \n",
    "    \n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu2, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9798.194336\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 7.5%\n",
      "Minibatch loss at step 500: 2180.100342\n",
      "Minibatch accuracy: 49.2%\n",
      "Validation accuracy: 71.1%\n",
      "Minibatch loss at step 1000: 1889.402710\n",
      "Minibatch accuracy: 51.6%\n",
      "Validation accuracy: 75.7%\n",
      "Minibatch loss at step 1500: 2102.829346\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 2000: 1606.990356\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 2500: 1101.307617\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3000: 1144.654663\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 79.1%\n",
      "Test accuracy: 86.5%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10161.313477\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 7.4%\n",
      "Minibatch loss at step 500: 2134.608643\n",
      "Minibatch accuracy: 46.1%\n",
      "Validation accuracy: 74.9%\n",
      "Minibatch loss at step 1000: 1437.886719\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 1500: 1470.571167\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 2000: 1249.877930\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 2500: 555.326050\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 3000: 753.598450\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.0%\n",
      "Test accuracy: 87.2%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10606.321289\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 7.8%\n",
      "Minibatch loss at step 500: 1823.441162\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 1000: 1203.505615\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 1500: 832.646973\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 903.633423\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 434.623779\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 3000: 481.156464\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.0%\n",
      "Test accuracy: 87.5%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9648.331055\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 11.4%\n",
      "Minibatch loss at step 500: 1575.626343\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1000: 734.723389\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1500: 858.122314\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2000: 848.934998\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2500: 450.061523\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 3000: 461.329620\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.1%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10559.673828\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.5%\n",
      "Minibatch loss at step 500: 1613.590332\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 1000: 706.792480\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 1500: 733.899719\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2000: 620.237244\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2500: 270.153381\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 3000: 255.922791\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9865.889648\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 9.6%\n",
      "Minibatch loss at step 500: 1234.459473\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1000: 779.602234\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1500: 503.881042\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2000: 414.024323\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2500: 241.718643\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 3000: 202.908890\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.8%\n",
      "Test accuracy: 86.5%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10331.352539\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 6.8%\n",
      "Minibatch loss at step 500: 1288.657104\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1000: 672.536194\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1500: 498.058868\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2000: 462.073151\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 173.065506\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 3000: 160.347336\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.4%\n",
      "Test accuracy: 87.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9936.511719\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 14.6%\n",
      "Minibatch loss at step 500: 855.093994\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1000: 618.851990\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1500: 458.732117\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2000: 295.656067\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 186.844971\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 3000: 159.502167\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.7%\n",
      "Test accuracy: 87.6%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9778.101562\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 12.5%\n",
      "Minibatch loss at step 500: 923.034058\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1000: 500.459686\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1500: 460.880463\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 296.105438\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2500: 153.088669\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 3000: 112.326477\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 79.3%\n",
      "Test accuracy: 86.1%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9069.224609\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.9%\n",
      "Minibatch loss at step 500: 2647.653564\n",
      "Minibatch accuracy: 39.8%\n",
      "Validation accuracy: 72.5%\n",
      "Minibatch loss at step 1000: 1605.243652\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 1500: 1728.314209\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 2000: 1411.548828\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 2500: 923.266846\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 3000: 825.545288\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.8%\n",
      "Test accuracy: 86.8%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10008.902344\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 11.1%\n",
      "Minibatch loss at step 500: 1792.994385\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 1000: 1272.074463\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1500: 1131.117676\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2000: 806.417664\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2500: 450.967926\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 3000: 566.868958\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.7%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8512.467773\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 8.0%\n",
      "Minibatch loss at step 500: 1233.125488\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 1000: 948.514526\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 1500: 1122.776001\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2000: 776.211121\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2500: 386.062500\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 3000: 472.188843\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.6%\n",
      "Test accuracy: 87.7%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7757.988770\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 8.9%\n",
      "Minibatch loss at step 500: 1245.866211\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 1000: 820.046326\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1500: 764.049744\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 581.328247\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 333.774261\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 3000: 407.087646\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7973.477539\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 14.0%\n",
      "Minibatch loss at step 500: 1059.444092\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 1000: 672.700073\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 620.808533\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2000: 453.628082\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 2500: 198.262695\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 3000: 272.440979\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.8%\n",
      "Test accuracy: 88.5%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7552.688965\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 11.2%\n",
      "Minibatch loss at step 500: 1137.850464\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 1000: 549.183777\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 604.217468\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 472.070221\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 212.102173\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 3000: 169.767090\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7109.307129\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 13.6%\n",
      "Minibatch loss at step 500: 1041.246216\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1000: 698.730591\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1500: 504.813843\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2000: 330.389893\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 167.353027\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 204.951157\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 87.6%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7221.476074\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 12.0%\n",
      "Minibatch loss at step 500: 807.193054\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1000: 545.255249\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1500: 476.122070\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2000: 362.023773\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2500: 147.484589\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 3000: 172.922623\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 87.9%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6605.560547\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 500: 880.631348\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1000: 519.486389\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 421.127655\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2000: 258.592163\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2500: 108.389435\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 116.192093\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 87.8%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6805.502930\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 11.0%\n",
      "Minibatch loss at step 500: 1546.529907\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 72.1%\n",
      "Minibatch loss at step 1000: 1018.748169\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1500: 1167.372437\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 2000: 1116.324951\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 2500: 551.741394\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 3000: 741.070679\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.6%\n",
      "Test accuracy: 87.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6600.955566\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.5%\n",
      "Minibatch loss at step 500: 1548.407593\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1000: 1122.065430\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 1500: 758.060303\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 2000: 886.971558\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 454.396912\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 3000: 470.094482\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.8%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7167.677246\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.2%\n",
      "Minibatch loss at step 500: 1332.541016\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 1000: 802.464355\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1500: 697.460754\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 603.550903\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 295.728638\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 475.767303\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.7%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6431.464844\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 8.6%\n",
      "Minibatch loss at step 500: 1097.360718\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1000: 732.258362\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1500: 803.693542\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 591.567566\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 255.534958\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 323.960266\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.4%\n",
      "Test accuracy: 88.6%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6845.608887\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 9.6%\n",
      "Minibatch loss at step 500: 972.155090\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 1000: 691.460205\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 432.305634\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 474.895477\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 194.036896\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 3000: 249.433853\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6467.701172\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.1%\n",
      "Minibatch loss at step 500: 975.145508\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 1000: 434.597137\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 365.627930\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 357.911133\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 182.653198\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 217.436707\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6311.518066\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 12.5%\n",
      "Minibatch loss at step 500: 726.334595\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1000: 565.567993\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1500: 506.048431\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2000: 413.910004\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2500: 106.702866\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 3000: 245.829956\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.1%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6580.181152\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 11.9%\n",
      "Minibatch loss at step 500: 632.350769\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1000: 473.347107\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 443.292847\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2000: 319.174194\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 137.785934\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 3000: 206.263489\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 88.3%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6228.297852\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 14.0%\n",
      "Minibatch loss at step 500: 751.942749\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1000: 399.883606\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1500: 374.785950\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2000: 332.261169\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 115.131607\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 125.186798\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.1%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4086.414062\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 12.5%\n",
      "Minibatch loss at step 500: 1204.000610\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 70.6%\n",
      "Minibatch loss at step 1000: 868.882935\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 1500: 689.338928\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 2000: 729.164673\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2500: 370.157898\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 3000: 501.470306\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.8%\n",
      "Test accuracy: 86.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5206.576660\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 5.8%\n",
      "Minibatch loss at step 500: 853.426697\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 1000: 481.290680\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 1500: 648.426636\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 2000: 627.143311\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 2500: 287.440033\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 3000: 446.195343\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.0%\n",
      "Test accuracy: 87.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5432.695801\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 11.9%\n",
      "Minibatch loss at step 500: 726.913269\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 1000: 624.112366\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1500: 476.635315\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 2000: 437.235809\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2500: 266.456390\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 3000: 314.754547\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6557.661621\n",
      "Minibatch accuracy: 3.1%\n",
      "Validation accuracy: 9.5%\n",
      "Minibatch loss at step 500: 844.826538\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 1000: 510.286896\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 1500: 444.915100\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2000: 469.239166\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2500: 228.016525\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 281.218384\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5535.287598\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 8.0%\n",
      "Minibatch loss at step 500: 474.460236\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 1000: 470.813629\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1500: 501.185638\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 364.825378\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2500: 190.565353\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 321.629639\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.4%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5770.687012\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 14.2%\n",
      "Minibatch loss at step 500: 510.778595\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 1000: 273.480682\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1500: 424.040436\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2000: 273.929657\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2500: 156.998505\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 217.402939\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.4%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4950.587891\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 11.8%\n",
      "Minibatch loss at step 500: 514.125427\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1000: 372.568512\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1500: 314.778900\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2000: 262.566132\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2500: 160.598267\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 3000: 250.943329\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.8%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5217.675781\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 11.5%\n",
      "Minibatch loss at step 500: 463.602814\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 370.294739\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 312.375031\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2000: 257.290253\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 144.214447\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 191.569061\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4044.347412\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 16.4%\n",
      "Minibatch loss at step 500: 527.315063\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 329.623108\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 319.350159\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2000: 302.321259\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 119.865036\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 129.524826\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 88.5%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5122.288086\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 13.7%\n",
      "Minibatch loss at step 500: 971.183594\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 69.8%\n",
      "Minibatch loss at step 1000: 797.081482\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 1500: 857.562134\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 2000: 750.571655\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 2500: 396.389832\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 3000: 524.271179\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.5%\n",
      "Test accuracy: 86.3%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5703.508301\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 8.1%\n",
      "Minibatch loss at step 500: 981.421448\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 1000: 700.640259\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 1500: 678.446533\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 2000: 666.627075\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2500: 333.805084\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 3000: 456.233582\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.5%\n",
      "Test accuracy: 87.4%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4953.209473\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 13.6%\n",
      "Minibatch loss at step 500: 711.682007\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 1000: 532.160034\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 1500: 571.733826\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2000: 511.072723\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2500: 246.698578\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 3000: 329.656708\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.9%\n",
      "Test accuracy: 87.8%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6136.625000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 7.8%\n",
      "Minibatch loss at step 500: 633.536316\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 1000: 468.929260\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 1500: 489.028107\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2000: 348.383606\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2500: 202.028595\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 421.044128\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.4%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4882.291016\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.8%\n",
      "Minibatch loss at step 500: 645.415039\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 1000: 500.046967\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1500: 526.675293\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2000: 341.603119\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 229.982590\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 3000: 219.056366\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.1%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5505.343750\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 9.1%\n",
      "Minibatch loss at step 500: 431.901428\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1000: 481.559967\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1500: 368.836090\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 339.535461\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 201.845840\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 3000: 211.806519\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.4%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5953.313965\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 10.9%\n",
      "Minibatch loss at step 500: 569.367004\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 1000: 306.741180\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1500: 440.610382\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2000: 309.123627\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2500: 124.720573\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 154.707077\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.0%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5329.741699\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 9.6%\n",
      "Minibatch loss at step 500: 447.958740\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 1000: 314.183899\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1500: 347.217010\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2000: 258.019012\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 83.604156\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 150.257507\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4398.051270\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 15.8%\n",
      "Minibatch loss at step 500: 364.014923\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 260.840149\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1500: 282.841217\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2000: 171.850861\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2500: 82.820030\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 3000: 142.251694\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 88.5%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5168.821289\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 7.6%\n",
      "Minibatch loss at step 500: 580.825317\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 67.1%\n",
      "Minibatch loss at step 1000: 622.723694\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 71.7%\n",
      "Minibatch loss at step 1500: 540.214844\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 2000: 444.565430\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 2500: 241.994781\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 3000: 432.540161\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 76.5%\n",
      "Test accuracy: 83.1%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6567.918945\n",
      "Minibatch accuracy: 3.1%\n",
      "Validation accuracy: 5.2%\n",
      "Minibatch loss at step 500: 625.339478\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 70.8%\n",
      "Minibatch loss at step 1000: 386.098938\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 1500: 392.937988\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 2000: 465.892029\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 2500: 223.024826\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 3000: 340.395050\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 77.6%\n",
      "Test accuracy: 85.1%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5087.463867\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 13.4%\n",
      "Minibatch loss at step 500: 492.664764\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss at step 1000: 406.090485\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1500: 416.026947\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 2000: 453.937225\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 2500: 187.200638\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3000: 267.530304\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 79.1%\n",
      "Test accuracy: 85.6%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5044.091309\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.8%\n",
      "Minibatch loss at step 500: 451.649811\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 1000: 379.030029\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 1500: 338.898682\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 2000: 321.955780\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2500: 169.082260\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 3000: 285.885040\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.8%\n",
      "Test accuracy: 86.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4228.061523\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 12.3%\n",
      "Minibatch loss at step 500: 345.268372\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 75.7%\n",
      "Minibatch loss at step 1000: 329.030640\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1500: 441.134125\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2000: 304.720520\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 2500: 117.636642\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 3000: 244.230560\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 79.9%\n",
      "Test accuracy: 87.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6644.072754\n",
      "Minibatch accuracy: 3.1%\n",
      "Validation accuracy: 7.2%\n",
      "Minibatch loss at step 500: 439.861023\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1000: 398.897095\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1500: 382.103363\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 2000: 309.695465\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 2500: 165.451721\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 3000: 195.151581\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.3%\n",
      "Test accuracy: 87.1%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4065.850098\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 15.1%\n",
      "Minibatch loss at step 500: 357.011047\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1000: 311.751740\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 1500: 333.238892\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 2000: 270.478546\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2500: 126.357147\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 3000: 225.729477\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.5%\n",
      "Test accuracy: 87.2%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4965.475098\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 251.819916\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1000: 275.166321\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1500: 357.609497\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 2000: 207.319733\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2500: 106.024132\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 3000: 160.078461\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.4%\n",
      "Test accuracy: 87.2%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5172.990234\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 13.6%\n",
      "Minibatch loss at step 500: 356.379059\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 1000: 300.542572\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1500: 317.412964\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 2000: 198.289597\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 92.596275\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 166.398285\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.9%\n",
      "Test accuracy: 87.6%\n",
      "{(0.7, 0.0006000000000000001): 88.230000000000004, (0.6, 0.0005): 88.549999999999997, (0.7, 0.00030000000000000003): 88.680000000000007, (0.7, 0.0007000000000000001): 88.140000000000001, (0.6, 0.0009000000000000001): 87.75, (0.5, 0.0004): 88.069999999999993, (0.6, 0.00030000000000000003): 87.680000000000007, (0.5, 0.0005): 88.239999999999995, (0.9, 0.0009000000000000001): 88.450000000000003, (0.6, 0.0007000000000000001): 87.590000000000003, (1.0, 0.0008): 87.180000000000007, (1.0, 0.0001): 83.090000000000003, (1.0, 0.00030000000000000003): 85.629999999999995, (0.5, 0.0006000000000000001): 86.459999999999994, (0.9, 0.0002): 87.379999999999995, (1.0, 0.0007000000000000001): 87.189999999999998, (0.9, 0.0001): 86.260000000000005, (0.7, 0.0002): 87.969999999999999, (0.5, 0.0002): 87.189999999999998, (0.9, 0.0007000000000000001): 88.230000000000004, (0.7, 0.0009000000000000001): 88.140000000000001, (0.5, 0.0008): 87.640000000000001, (0.6, 0.0004): 88.25, (0.6, 0.0002): 88.030000000000001, (0.5, 0.0007000000000000001): 86.980000000000004, (1.0, 0.0006000000000000001): 87.099999999999994, (0.6, 0.0001): 86.769999999999996, (0.9, 0.0008): 88.030000000000001, (0.9, 0.00030000000000000003): 87.810000000000002, (1.0, 0.0004): 85.950000000000003, (0.5, 0.0009000000000000001): 86.129999999999995, (0.7, 0.0005): 88.230000000000004, (0.5, 0.00030000000000000003): 87.549999999999997, (0.5, 0.0001): 86.519999999999996, (0.6, 0.0006000000000000001): 88.180000000000007, (0.9, 0.0005): 88.109999999999999, (0.9, 0.0004): 88.180000000000007, (1.0, 0.0009000000000000001): 87.620000000000005, (0.7, 0.0001): 86.980000000000004, (0.9, 0.0006000000000000001): 88.409999999999997, (0.7, 0.0008): 88.310000000000002, (0.7, 0.0004): 88.620000000000005, (0.6, 0.0008): 87.939999999999998, (1.0, 0.0002): 85.069999999999993, (1.0, 0.0005): 86.969999999999999}\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "scores = {}\n",
    "for kp in [0.5, 0.6, 0.7, 0.9, 0.9, 1.0]:\n",
    "    for lr in np.arange(0.0001, 0.001, 0.0001).tolist():\n",
    "        print(\">> with keep prob of \" + str(kp))\n",
    "        print(\">> with lr  \" + str(lr))\n",
    "        with tf.Session(graph=graph) as session:\n",
    "          tf.initialize_all_variables().run()\n",
    "          print(\"Initialized\")\n",
    "          for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : kp, learnr : lr}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict )\n",
    "            if (step % 500 == 0):\n",
    "              print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "              print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "              print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "          acc = accuracy(test_prediction.eval(), test_labels)\n",
    "          scores[(kp, lr)] = acc\n",
    "          print(\"Test accuracy: %.1f%%\" % acc)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying 2 NN with different loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "hidden_nodes1 = 1024\n",
    "hidden_nodes2 = 512\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer 1\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes1]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes1]))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "    \n",
    "    # new hidden layer 2\n",
    "    hidden_weights2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2]) )\n",
    "    hidden_biases2 = tf.Variable(tf.zeros([hidden_nodes2]))\n",
    "    hidden_layer2 = tf.nn.relu(tf.matmul( hidden_layer_drop, hidden_weights2) + hidden_biases2)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    hidden_layer_drop2 = tf.nn.dropout(hidden_layer2, keep_prob)\n",
    "    \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_nodes2, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop2, weights) + biases\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * ( tf.nn.l2_loss(weights) + tf.nn.l2_loss(hidden_weights) + tf.nn.l2_loss(hidden_weights2) ))\n",
    "\n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learnr = tf.placeholder(\"float\")\n",
    "    learning_rate = tf.train.exponential_decay(learnr, global_step, 100000, 0.95, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step= global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)    \n",
    "    \n",
    "    valid_relu1 = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)    \n",
    "    valid_relu2 = tf.nn.relu(tf.matmul(valid_relu1, hidden_weights2) + hidden_biases2)    \n",
    "    \n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(valid_relu2, weights) + biases) \n",
    "    \n",
    "    test_relu1 = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_relu2 = tf.nn.relu(tf.matmul(test_relu1, hidden_weights2) + hidden_biases2)   \n",
    "    \n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu2, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9403.234375\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.2%\n",
      "Minibatch loss at step 500: 3556.572266\n",
      "Minibatch accuracy: 39.8%\n",
      "Validation accuracy: 71.3%\n",
      "Minibatch loss at step 1000: 2401.669434\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 1500: 2176.594238\n",
      "Minibatch accuracy: 53.9%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 2000: 2425.125488\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2500: 1625.495605\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 3000: 1798.953857\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 79.5%\n",
      "Test accuracy: 86.5%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10078.695312\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 13.3%\n",
      "Minibatch loss at step 500: 3001.082764\n",
      "Minibatch accuracy: 50.8%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1000: 1939.378052\n",
      "Minibatch accuracy: 53.9%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 1500: 1642.836670\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 2000: 1525.809082\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2500: 1296.896484\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 3000: 1411.951416\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 80.3%\n",
      "Test accuracy: 87.6%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10167.828125\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 11.1%\n",
      "Minibatch loss at step 500: 2292.916016\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1000: 1553.931763\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1500: 1724.820801\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2000: 1486.229370\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2500: 937.128418\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 3000: 1092.401245\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 80.2%\n",
      "Test accuracy: 87.3%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 11919.576172\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 6.1%\n",
      "Minibatch loss at step 500: 2115.696045\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1000: 1387.542725\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 1250.385498\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2000: 1295.159546\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 828.741577\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 3000: 901.118286\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 87.6%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 12189.337891\n",
      "Minibatch accuracy: 3.1%\n",
      "Validation accuracy: 5.3%\n",
      "Minibatch loss at step 500: 2023.307983\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1000: 1173.960327\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1500: 1247.417236\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2000: 1020.522705\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 824.883667\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 3000: 737.686157\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.8%\n",
      "Test accuracy: 87.9%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10523.019531\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 11.4%\n",
      "Minibatch loss at step 500: 1715.574585\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 1000: 1239.855957\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1500: 974.760498\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2000: 1025.820312\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 760.479126\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 3000: 699.080078\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.3%\n",
      "Test accuracy: 87.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9294.229492\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 9.3%\n",
      "Minibatch loss at step 500: 1817.238037\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1000: 1133.719116\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1500: 993.360596\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2000: 891.264709\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2500: 686.138306\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 3000: 747.947510\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 80.7%\n",
      "Test accuracy: 87.8%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10382.666992\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 11.4%\n",
      "Minibatch loss at step 500: 1754.820557\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1000: 1112.151245\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1500: 977.320496\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 846.078857\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2500: 674.265442\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 683.894470\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 80.1%\n",
      "Test accuracy: 87.2%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9989.073242\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 13.7%\n",
      "Minibatch loss at step 500: 1464.640381\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1000: 1079.155762\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1500: 944.350098\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 776.323853\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2500: 620.340149\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 606.724487\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.5%\n",
      "Test accuracy: 87.4%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9150.125977\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 11.8%\n",
      "Minibatch loss at step 500: 2914.477295\n",
      "Minibatch accuracy: 41.4%\n",
      "Validation accuracy: 72.1%\n",
      "Minibatch loss at step 1000: 2121.760986\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1500: 2070.799316\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 2000: 1886.926270\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2500: 1355.366577\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 3000: 1352.789917\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.2%\n",
      "Test accuracy: 86.8%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9087.625977\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 9.5%\n",
      "Minibatch loss at step 500: 2526.868164\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1000: 1827.357422\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 1500: 1737.737549\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 1271.279297\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 1126.420166\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 1139.061890\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 81.0%\n",
      "Test accuracy: 88.1%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8762.829102\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 6.3%\n",
      "Minibatch loss at step 500: 1867.553711\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1000: 1331.779053\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 1500: 1355.330444\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2000: 1403.852661\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 998.417969\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 983.348267\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 87.7%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8188.047852\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 500: 1670.059570\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1000: 1383.419922\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1500: 1259.068359\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 971.926758\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2500: 903.414978\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 3000: 841.973328\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 88.7%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8114.600586\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 500: 1690.557129\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1000: 1173.429199\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1500: 1157.671143\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2000: 1011.087646\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2500: 766.744751\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 3000: 739.716187\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.0%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9681.402344\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 12.6%\n",
      "Minibatch loss at step 500: 1412.091797\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 1000: 1140.527222\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 1135.373901\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 1061.948364\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 736.898743\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 753.794556\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 87.7%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8980.013672\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 9.4%\n",
      "Minibatch loss at step 500: 1286.167725\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 1077.222290\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1500: 882.657959\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2000: 835.189209\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 701.321167\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 3000: 706.311951\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 88.3%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8501.630859\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.2%\n",
      "Minibatch loss at step 500: 1191.279297\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1000: 996.748291\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 1002.588867\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2000: 869.106201\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 685.343506\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 640.265015\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.9%\n",
      "Test accuracy: 87.6%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9717.831055\n",
      "Minibatch accuracy: 3.9%\n",
      "Validation accuracy: 9.6%\n",
      "Minibatch loss at step 500: 1348.262695\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1000: 905.453247\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 848.355652\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2000: 817.996826\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 600.537964\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 651.978638\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.0%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8879.535156\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 13.6%\n",
      "Minibatch loss at step 500: 2751.926758\n",
      "Minibatch accuracy: 45.3%\n",
      "Validation accuracy: 72.0%\n",
      "Minibatch loss at step 1000: 1826.386108\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 1500: 1733.771118\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 2000: 1472.415161\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 2500: 1223.925171\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 3000: 1522.638916\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.5%\n",
      "Test accuracy: 86.5%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7498.677734\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.9%\n",
      "Minibatch loss at step 500: 1984.451050\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 1000: 1578.545166\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 1500: 1412.044922\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 2000: 1187.534058\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2500: 889.073364\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 3000: 1088.223389\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.3%\n",
      "Test accuracy: 87.8%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8890.026367\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 14.2%\n",
      "Minibatch loss at step 500: 1735.521606\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 1000: 1221.188110\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 1500: 1230.044434\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2000: 1123.402832\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 845.431396\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 3000: 955.593872\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8948.488281\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 11.5%\n",
      "Minibatch loss at step 500: 1642.417847\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 1000: 1175.362793\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1500: 1167.838623\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 1145.412231\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 888.886353\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 3000: 847.262085\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 82.0%\n",
      "Test accuracy: 88.7%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7868.962402\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 9.3%\n",
      "Minibatch loss at step 500: 1305.089600\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 1000: 1163.896973\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1500: 1168.768311\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2000: 909.965454\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 731.952271\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 3000: 765.910522\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 88.4%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7176.814453\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 12.4%\n",
      "Minibatch loss at step 500: 1282.659912\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 962.805176\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 1069.163330\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2000: 967.092651\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2500: 720.709656\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 3000: 691.293762\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.8%\n",
      "Test accuracy: 88.8%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7847.564453\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 13.5%\n",
      "Minibatch loss at step 500: 1302.795166\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1000: 1028.331543\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1500: 937.507629\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2000: 871.503784\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2500: 706.555298\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 3000: 694.966675\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.4%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7500.075684\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 16.3%\n",
      "Minibatch loss at step 500: 1117.217773\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1000: 1055.612549\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1500: 932.229492\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2000: 710.176392\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 689.021057\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 647.379517\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 87.7%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 7894.250000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 15.1%\n",
      "Minibatch loss at step 500: 1139.933105\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1000: 909.788452\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1500: 900.450745\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2000: 806.365540\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2500: 574.455872\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 670.753540\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 81.0%\n",
      "Test accuracy: 88.5%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5082.997559\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 7.1%\n",
      "Minibatch loss at step 500: 1678.783936\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 68.6%\n",
      "Minibatch loss at step 1000: 1359.039307\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 1500: 1373.153564\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 2000: 1359.471924\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2500: 943.009338\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 3000: 997.725830\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 78.5%\n",
      "Test accuracy: 86.1%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5075.370117\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 6.2%\n",
      "Minibatch loss at step 500: 1152.086670\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 74.6%\n",
      "Minibatch loss at step 1000: 1111.949707\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1500: 1055.024658\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 2000: 1043.301147\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 2500: 737.547729\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 3000: 964.206787\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.2%\n",
      "Test accuracy: 87.1%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6300.382324\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 12.5%\n",
      "Minibatch loss at step 500: 1343.437988\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1000: 1103.557861\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1500: 1228.286865\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2000: 1024.256714\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 771.093872\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 3000: 882.419312\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.8%\n",
      "Test accuracy: 87.4%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5246.146484\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 17.4%\n",
      "Minibatch loss at step 500: 1205.083740\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1000: 1057.970703\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 1500: 1000.422729\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2000: 900.717651\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2500: 736.189087\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 3000: 817.522949\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.7%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5129.097168\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 9.0%\n",
      "Minibatch loss at step 500: 1072.802612\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 1000: 857.573486\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 1500: 951.197998\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2000: 810.355347\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 633.386780\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 3000: 710.982788\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.1%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6725.837891\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 12.7%\n",
      "Minibatch loss at step 500: 985.181885\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 1000: 848.477234\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1500: 925.349731\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2000: 826.038940\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2500: 682.773071\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 3000: 708.755798\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6564.530273\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 13.5%\n",
      "Minibatch loss at step 500: 1033.829102\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1000: 864.893433\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1500: 967.824097\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2000: 770.945984\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 628.541260\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 766.457336\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.8%\n",
      "Test accuracy: 88.6%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4892.428223\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 11.4%\n",
      "Minibatch loss at step 500: 1002.416992\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 1000: 865.804138\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1500: 800.442993\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 760.204163\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 624.996460\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 687.194031\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 88.3%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5318.567383\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 14.3%\n",
      "Minibatch loss at step 500: 1000.946472\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 1000: 815.925903\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1500: 798.777222\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2000: 742.904297\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 611.132324\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 698.054871\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 88.3%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4702.708496\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 12.4%\n",
      "Minibatch loss at step 500: 1438.050537\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 70.0%\n",
      "Minibatch loss at step 1000: 1191.766113\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 1500: 1258.613647\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 2000: 1171.689941\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 2500: 831.752075\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 3000: 1092.270020\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 78.3%\n",
      "Test accuracy: 85.7%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6002.271484\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 9.5%\n",
      "Minibatch loss at step 500: 1432.598877\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 74.9%\n",
      "Minibatch loss at step 1000: 1214.459961\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1500: 1260.766602\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2000: 1002.026611\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 2500: 851.420288\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 3000: 976.720154\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.8%\n",
      "Test accuracy: 87.5%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5484.053711\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 14.3%\n",
      "Minibatch loss at step 500: 1373.517090\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 1000: 1198.378174\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 1500: 1097.501221\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 1127.200439\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2500: 773.731628\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 3000: 975.628540\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.8%\n",
      "Test accuracy: 87.5%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6000.479492\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 14.7%\n",
      "Minibatch loss at step 500: 1218.088135\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1000: 1114.298340\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 1500: 1100.502441\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2000: 868.746765\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 762.903992\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 3000: 857.128113\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Test accuracy: 88.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8475.938477\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 500: 894.081787\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1000: 986.408081\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1500: 782.521973\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2000: 859.664978\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2500: 727.040771\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 703.650208\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4786.703613\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 11.4%\n",
      "Minibatch loss at step 500: 845.163574\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 1000: 979.583496\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1500: 865.721741\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2000: 814.666016\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2500: 670.139893\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 3000: 702.164062\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 88.4%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6784.679199\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.5%\n",
      "Minibatch loss at step 500: 1084.518677\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 1000: 910.972961\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1500: 865.936401\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 781.337036\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 612.115784\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 648.670898\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 88.3%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5595.854004\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 7.1%\n",
      "Minibatch loss at step 500: 1052.021973\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 1000: 923.311646\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1500: 869.526245\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 800.061035\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 631.396240\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 682.253357\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.2%\n",
      "Test accuracy: 88.5%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5232.274414\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 8.0%\n",
      "Minibatch loss at step 500: 878.663818\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 863.131592\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 783.474121\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2000: 754.075623\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2500: 625.406616\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 3000: 638.648132\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 88.2%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6161.688477\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 9.4%\n",
      "Minibatch loss at step 500: 1311.600342\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 65.7%\n",
      "Minibatch loss at step 1000: 1181.371582\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 70.8%\n",
      "Minibatch loss at step 1500: 1204.506104\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 73.0%\n",
      "Minibatch loss at step 2000: 1016.952087\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 2500: 817.549133\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 75.1%\n",
      "Minibatch loss at step 3000: 857.554016\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 75.6%\n",
      "Test accuracy: 83.1%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4275.923828\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.6%\n",
      "Minibatch loss at step 500: 1016.534668\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 71.5%\n",
      "Minibatch loss at step 1000: 974.088135\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 1500: 1027.898193\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 2000: 837.362671\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2500: 820.052856\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 3000: 852.872070\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.1%\n",
      "Test accuracy: 84.9%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6921.915039\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 9.4%\n",
      "Minibatch loss at step 500: 1021.662598\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 73.4%\n",
      "Minibatch loss at step 1000: 860.445007\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1500: 962.358643\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2000: 870.457642\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 2500: 645.387756\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3000: 787.038269\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.0%\n",
      "Test accuracy: 86.3%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5499.064941\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 12.1%\n",
      "Minibatch loss at step 500: 968.993164\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 74.3%\n",
      "Minibatch loss at step 1000: 892.299255\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 1500: 855.158142\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2000: 863.075928\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 2500: 672.388184\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 3000: 700.326294\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 78.9%\n",
      "Test accuracy: 86.6%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6041.814941\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 12.0%\n",
      "Minibatch loss at step 500: 957.295166\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 1000: 887.130920\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1500: 936.233765\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2000: 839.330261\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 2500: 658.038208\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 3000: 791.490479\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.6%\n",
      "Test accuracy: 87.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6355.633789\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 9.1%\n",
      "Minibatch loss at step 500: 892.339844\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 1000: 806.940552\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 1500: 830.868774\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 2000: 715.003540\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 2500: 633.876221\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 3000: 713.886475\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.7%\n",
      "Test accuracy: 86.7%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6209.925293\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 11.3%\n",
      "Minibatch loss at step 500: 892.114990\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1000: 795.283813\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 1500: 786.736633\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 2000: 739.254456\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2500: 650.473145\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 3000: 691.914062\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.0%\n",
      "Test accuracy: 87.4%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4625.547363\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 17.2%\n",
      "Minibatch loss at step 500: 913.029236\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 811.777649\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 1500: 892.978027\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 2000: 714.284546\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2500: 628.952393\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 3000: 665.762451\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.3%\n",
      "Test accuracy: 87.3%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4688.828125\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 8.7%\n",
      "Minibatch loss at step 500: 765.697083\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 795.913818\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 1500: 785.515320\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2000: 660.800659\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2500: 597.093140\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 3000: 662.910522\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.5%\n",
      "Test accuracy: 88.0%\n",
      "{(0.7, 0.0006000000000000001): 88.769999999999996, (0.6, 0.0005): 88.019999999999996, (0.7, 0.00030000000000000003): 87.959999999999994, (0.7, 0.0007000000000000001): 88.219999999999999, (0.6, 0.0009000000000000001): 88.239999999999995, (0.5, 0.0004): 87.620000000000005, (0.6, 0.00030000000000000003): 87.719999999999999, (0.5, 0.0005): 87.920000000000002, (0.9, 0.0009000000000000001): 88.150000000000006, (0.6, 0.0007000000000000001): 88.340000000000003, (1.0, 0.0008): 87.280000000000001, (1.0, 0.0001): 83.120000000000005, (1.0, 0.00030000000000000003): 86.310000000000002, (0.5, 0.0006000000000000001): 87.0, (0.9, 0.0002): 87.450000000000003, (1.0, 0.0007000000000000001): 87.409999999999997, (0.9, 0.0001): 85.730000000000004, (0.7, 0.0002): 87.799999999999997, (0.5, 0.0002): 87.640000000000001, (0.9, 0.0007000000000000001): 88.310000000000002, (0.7, 0.0009000000000000001): 88.469999999999999, (0.5, 0.0008): 87.230000000000004, (0.6, 0.0004): 88.739999999999995, (0.6, 0.0002): 88.120000000000005, (0.5, 0.0007000000000000001): 87.819999999999993, (1.0, 0.0006000000000000001): 86.709999999999994, (0.6, 0.0001): 86.760000000000005, (0.9, 0.0008): 88.489999999999995, (0.9, 0.00030000000000000003): 87.459999999999994, (1.0, 0.0004): 86.620000000000005, (0.5, 0.0009000000000000001): 87.430000000000007, (0.7, 0.0005): 88.420000000000002, (0.5, 0.00030000000000000003): 87.290000000000006, (0.5, 0.0001): 86.530000000000001, (0.6, 0.0006000000000000001): 87.689999999999998, (0.9, 0.0005): 88.189999999999998, (0.9, 0.0004): 87.989999999999995, (1.0, 0.0009000000000000001): 88.049999999999997, (0.7, 0.0001): 86.5, (0.9, 0.0006000000000000001): 88.359999999999999, (0.7, 0.0008): 87.680000000000007, (0.7, 0.0004): 88.709999999999994, (0.6, 0.0008): 87.560000000000002, (1.0, 0.0002): 84.939999999999998, (1.0, 0.0005): 87.019999999999996}\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "scores = {}\n",
    "for kp in [0.5, 0.6, 0.7, 0.9, 0.9, 1.0]:\n",
    "    for lr in np.arange(0.0001, 0.001, 0.0001).tolist():\n",
    "        print(\">> with keep prob of \" + str(kp))\n",
    "        print(\">> with lr  \" + str(lr))\n",
    "        with tf.Session(graph=graph) as session:\n",
    "          tf.initialize_all_variables().run()\n",
    "          print(\"Initialized\")\n",
    "          for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : kp, learnr : lr}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict )\n",
    "            if (step % 500 == 0):\n",
    "              print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "              print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "              print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "          acc = accuracy(test_prediction.eval(), test_labels)\n",
    "          scores[(kp, lr)] = acc\n",
    "          print(\"Test accuracy: %.1f%%\" % acc)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying NN with 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta = 0.001\n",
    "\n",
    "hidden_nodes1 = 1024\n",
    "hidden_nodes2 = 512\n",
    "hidden_nodes3 = 256\n",
    "hidden_nodes4 = 128\n",
    "hidden_nodes5 = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # new hidden layer 1\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes1]) )\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_nodes1]))\n",
    "    hidden_layer = tf.nn.relu(tf.matmul( tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    # add dropout on hidden layer\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_drop = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "    \n",
    "    # new hidden layer 2\n",
    "    hidden_weights2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2]) )\n",
    "    hidden_biases2 = tf.Variable(tf.zeros([hidden_nodes2]))\n",
    "    hidden_layer2 = tf.nn.relu(tf.matmul(hidden_layer_drop, hidden_weights2) + hidden_biases2)\n",
    "    \n",
    "    # add dropout on hidden layer 2\n",
    "    hidden_layer_drop2 = tf.nn.dropout(hidden_layer2, keep_prob)\n",
    "    \n",
    "    # new hidden layer 3\n",
    "    hidden_weights3 = tf.Variable(tf.truncated_normal([hidden_nodes2, hidden_nodes3]) )\n",
    "    hidden_biases3 = tf.Variable(tf.zeros([hidden_nodes3]))\n",
    "    hidden_layer3 = tf.nn.relu(tf.matmul(hidden_layer_drop2, hidden_weights3) + hidden_biases3)\n",
    "    \n",
    "    # add dropout on hidden layer 3\n",
    "    hidden_layer_drop3 = tf.nn.dropout(hidden_layer3, keep_prob)\n",
    "    \n",
    "    # new hidden layer 4\n",
    "    hidden_weights4 = tf.Variable(tf.truncated_normal([hidden_nodes3, hidden_nodes4]) )\n",
    "    hidden_biases4 = tf.Variable(tf.zeros([hidden_nodes4]))\n",
    "    hidden_layer4 = tf.nn.relu(tf.matmul(hidden_layer_drop3, hidden_weights4) + hidden_biases4)\n",
    "    \n",
    "    # add dropout on hidden layer 4\n",
    "    hidden_layer_drop4 = tf.nn.dropout(hidden_layer4, keep_prob)\n",
    "    \n",
    "    # new hidden layer 5\n",
    "    hidden_weights5 = tf.Variable(tf.truncated_normal([hidden_nodes4, hidden_nodes5]) )\n",
    "    hidden_biases5 = tf.Variable(tf.zeros([hidden_nodes5]))\n",
    "    hidden_layer5 = tf.nn.relu(tf.matmul( hidden_layer_drop4, hidden_weights5) + hidden_biases5)\n",
    "    \n",
    "    # add dropout on hidden layer 5\n",
    "    hidden_layer_drop5 = tf.nn.dropout(hidden_layer5, keep_prob)\n",
    "    \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_nodes5, num_labels])) \n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_layer_drop5, weights) + biases\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) )\n",
    "    loss = tf.reduce_mean(loss + beta * tf.nn.l2_loss(weights) )\n",
    "\n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learnr = tf.placeholder(\"float\")\n",
    "    learning_rate = tf.train.exponential_decay(learnr, global_step, 100000, 0.95, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step= global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)    \n",
    "    \n",
    "    valid_relu1 = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)    \n",
    "    valid_relu2 = tf.nn.relu(tf.matmul(valid_relu1, hidden_weights2) + hidden_biases2)  \n",
    "    valid_relu3 = tf.nn.relu(tf.matmul(valid_relu2, hidden_weights3) + hidden_biases3)   \n",
    "    valid_relu4 = tf.nn.relu(tf.matmul(valid_relu3, hidden_weights4) + hidden_biases4)\n",
    "    valid_relu5 = tf.nn.relu(tf.matmul(valid_relu4, hidden_weights5) + hidden_biases5)   \n",
    "    \n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(valid_relu5, weights) + biases) \n",
    "    \n",
    "    test_relu1 = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_relu2 = tf.nn.relu(tf.matmul(test_relu1, hidden_weights2) + hidden_biases2)   \n",
    "    test_relu3 = tf.nn.relu(tf.matmul(test_relu2, hidden_weights3) + hidden_biases3)  \n",
    "    test_relu4 = tf.nn.relu(tf.matmul(test_relu3, hidden_weights4) + hidden_biases4)   \n",
    "    test_relu5 = tf.nn.relu(tf.matmul(test_relu4, hidden_weights5) + hidden_biases5)  \n",
    "    \n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_relu5, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8755446.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10600961.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 11362382575572250263552.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 11360318801043007733760.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 11358255026513765203968.000000\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 11356191251984522674176.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 11354127477455280144384.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 11352062577026130771968.000000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9716798.000000\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 2718494312959335186827313152.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 2717691510657247347140984832.000000\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 2716888413207254328101830656.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 2716085906053071667768328192.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 2715283103750983828081999872.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 2714480891744706347101323264.000000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9767197.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 103195174916563702484294275432448.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 103152330585516560026342688555008.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 103109486254469417568391101677568.000000\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 103066641923422275110439514800128.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 103023816935188246486554723221504.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 102981011289767331696736726941696.000000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10789742.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: inf\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: inf\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: inf\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: inf\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8668102.000000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8633779.000000\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 9317500.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.5\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 8697764.000000\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6623991.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4941035.500000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6399760.000000\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6267675.000000\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 1071450402185512388846113783808.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 1071022140213913906460974120960.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 1070593878242315424075834458112.000000\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 1070165691828580667605018214400.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 1069737732088437088877172228096.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 1069309847906157236063649660928.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5442299.000000\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 62155594030504472647212990464.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 62123788892242345586698747904.000000\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 62091997921079667135120146432.000000\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 62060216394649954422831972352.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 62028444312953207449834225664.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 61996662786523494737546051584.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5150884.500000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5220183.500000\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: inf\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: inf\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: inf\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: inf\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 6248953.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: inf\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: inf\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: inf\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: inf\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.6\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 5959496.500000\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3997073.250000\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3751869.750000\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 64763437836533926228656128.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 64750377541729739866112000.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 64737308023553516648792064.000000\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 64724252340435348713635840.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 64711187433945143923703808.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 64698131750826975988547584.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3357928.000000\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2916518.250000\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3244155.500000\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 10745485201613319853278494720.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 10739843154257911344659431424.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 10734203468085744270862974976.000000\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 10728567323688439349300428800.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 10722929998699513710326579200.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 10717293854302208788764033024.000000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4041905.250000\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 2651199622814434675090012218851328.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 2649613821624110102957866440720384.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 2648028329918795352170789387370496.000000\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 2646443147698490422728781058801664.000000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 2644858893933214957321978904576000.000000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 2643274640167939491915176750350336.000000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4289195.500000\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: inf\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: inf\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: inf\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: inf\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: inf\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4116375.250000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: inf\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: inf\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: inf\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: inf\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: inf\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.7\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4666781.500000\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3072330.750000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1979620.500000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 9.5%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3028335.750000\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1858128.250000\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1865743.250000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2513549.000000\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2348490.750000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2244200.250000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: inf\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: inf\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: inf\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: inf\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: inf\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2009661.250000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: inf\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: inf\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: inf\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: inf\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2356437.250000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 11.5%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1910301.125000\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: inf\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: inf\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: inf\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: inf\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: inf\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: inf\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2536050.250000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2430635.750000\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2757731.750000\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1562620.500000\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2287737.000000\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2001400.750000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 0.9\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1550197.875000\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1247016.500000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0002\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1983702.000000\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.00030000000000000003\n",
      "Initialized\n",
      "Minibatch loss at step 0: 904342.062500\n",
      "Minibatch accuracy: 3.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0004\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1690328.625000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0005\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1819938.375000\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0006000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1961542.000000\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0007000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2817464.750000\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0008\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2171589.000000\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      ">> with keep prob of 1.0\n",
      ">> with lr  0.0009000000000000001\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1470948.250000\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Test accuracy: 10.0%\n",
      "{(0.7, 0.0006000000000000001): 10.0, (0.6, 0.0005): 10.0, (0.7, 0.00030000000000000003): 10.0, (0.7, 0.0007000000000000001): 10.0, (0.6, 0.0009000000000000001): 10.0, (0.5, 0.0004): 10.0, (0.6, 0.00030000000000000003): 10.0, (0.5, 0.0005): 10.0, (0.9, 0.0009000000000000001): 10.0, (0.6, 0.0007000000000000001): 10.0, (1.0, 0.0008): 10.0, (1.0, 0.0001): 10.0, (1.0, 0.00030000000000000003): 10.0, (0.5, 0.0006000000000000001): 10.0, (0.9, 0.0002): 10.0, (1.0, 0.0007000000000000001): 10.0, (0.9, 0.0001): 10.0, (0.7, 0.0002): 10.0, (0.5, 0.0002): 10.0, (0.9, 0.0007000000000000001): 10.0, (0.7, 0.0009000000000000001): 10.0, (0.5, 0.0008): 10.0, (0.6, 0.0004): 10.0, (0.6, 0.0002): 10.0, (0.5, 0.0007000000000000001): 10.0, (1.0, 0.0006000000000000001): 10.0, (0.6, 0.0001): 10.0, (0.9, 0.0008): 10.0, (0.9, 0.00030000000000000003): 10.0, (1.0, 0.0004): 10.0, (0.5, 0.0009000000000000001): 10.0, (0.7, 0.0005): 10.0, (0.5, 0.00030000000000000003): 10.0, (0.5, 0.0001): 10.0, (0.6, 0.0006000000000000001): 10.0, (0.9, 0.0005): 10.0, (0.9, 0.0004): 10.0, (1.0, 0.0009000000000000001): 10.0, (0.7, 0.0001): 10.0, (0.9, 0.0006000000000000001): 10.0, (0.7, 0.0008): 10.0, (0.7, 0.0004): 10.0, (0.6, 0.0008): 10.0, (1.0, 0.0002): 10.0, (1.0, 0.0005): 10.0}\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "scores = {}\n",
    "for kp in [0.5, 0.6, 0.7, 0.9, 0.9, 1.0]:\n",
    "    for lr in np.arange(0.0001, 0.001, 0.0001).tolist():\n",
    "        print(\">> with keep prob of \" + str(kp))\n",
    "        print(\">> with lr  \" + str(lr))\n",
    "        with tf.Session(graph=graph) as session:\n",
    "          tf.initialize_all_variables().run()\n",
    "          print(\"Initialized\")\n",
    "          for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : kp, learnr : lr}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict )\n",
    "            if (step % 500 == 0):\n",
    "              print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "              print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "              print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "          acc = accuracy(test_prediction.eval(), test_labels)\n",
    "          scores[(kp, lr)] = acc\n",
    "          print(\"Test accuracy: %.1f%%\" % acc)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
